{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('ggplot')\n",
    "\n",
    "bl = pd.read_csv('~/Documents/datasets/football/D1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [ 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG',\n",
    "       'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC',\n",
    "       'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A']\n",
    "data = bl[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Home team win rate\n",
    "n_matches = data.shape[0]\n",
    "\n",
    "n_features = data.shape[1] - 1\n",
    "\n",
    "n_homewins = len(data[data['FTR'] == 'H'])\n",
    "\n",
    "win_rate = ((n_homewins) / (n_matches)) * 100\n",
    "\n",
    "win_rate\n",
    "n_matches\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['HomeTeam','AwayTeam','FTR','HTR']\n",
    "num_features = ['FTHG', 'FTAG', 'HTHG', 'HTAG',\n",
    "     'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC',\n",
    "       'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = data.drop(\"FTR\",1)\n",
    "y_all = data[\"FTR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardising the data\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#Center to the mean and component wise scale to unit variance\n",
    "for col in num_features:\n",
    "    X_all[col] = scale(X_all[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed feature columns (58 total_features):\n",
      "['HomeTeam_Augsburg', 'HomeTeam_Bayern Munich', 'HomeTeam_Dortmund', 'HomeTeam_Ein Frankfurt', 'HomeTeam_FC Koln', 'HomeTeam_Freiburg', 'HomeTeam_Hamburg', 'HomeTeam_Hannover', 'HomeTeam_Hertha', 'HomeTeam_Hoffenheim', 'HomeTeam_Leverkusen', \"HomeTeam_M'gladbach\", 'HomeTeam_Mainz', 'HomeTeam_RB Leipzig', 'HomeTeam_Schalke 04', 'HomeTeam_Stuttgart', 'HomeTeam_Werder Bremen', 'HomeTeam_Wolfsburg', 'AwayTeam_Augsburg', 'AwayTeam_Bayern Munich', 'AwayTeam_Dortmund', 'AwayTeam_Ein Frankfurt', 'AwayTeam_FC Koln', 'AwayTeam_Freiburg', 'AwayTeam_Hamburg', 'AwayTeam_Hannover', 'AwayTeam_Hertha', 'AwayTeam_Hoffenheim', 'AwayTeam_Leverkusen', \"AwayTeam_M'gladbach\", 'AwayTeam_Mainz', 'AwayTeam_RB Leipzig', 'AwayTeam_Schalke 04', 'AwayTeam_Stuttgart', 'AwayTeam_Werder Bremen', 'AwayTeam_Wolfsburg', 'FTHG', 'FTAG', 'HTHG', 'HTAG', 'HTR_A', 'HTR_D', 'HTR_H', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A'] \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#preprocessing categorical features\n",
    "def preprocess_features(X):\n",
    "    ''' Preprocess data and convert all categorical features to dummies'''\n",
    "    #Initalise new output dataframe\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "    \n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data is categorical,convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data,prefix = col)\n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print(\"Preprocessed feature columns ({} total_features):\\n{} \".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = StandardScaler().fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.242536</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789936</td>\n",
       "      <td>-0.421483</td>\n",
       "      <td>0.300799</td>\n",
       "      <td>-0.421667</td>\n",
       "      <td>0.139960</td>\n",
       "      <td>-0.278325</td>\n",
       "      <td>-0.271448</td>\n",
       "      <td>-0.756455</td>\n",
       "      <td>1.588575</td>\n",
       "      <td>2.261191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.543534</td>\n",
       "      <td>-0.788929</td>\n",
       "      <td>1.141388</td>\n",
       "      <td>1.842020</td>\n",
       "      <td>0.933068</td>\n",
       "      <td>-0.278325</td>\n",
       "      <td>-0.271448</td>\n",
       "      <td>-0.292927</td>\n",
       "      <td>-0.457218</td>\n",
       "      <td>-0.225818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442074</td>\n",
       "      <td>-0.054036</td>\n",
       "      <td>-1.380379</td>\n",
       "      <td>0.332895</td>\n",
       "      <td>-0.653148</td>\n",
       "      <td>-0.278325</td>\n",
       "      <td>-0.271448</td>\n",
       "      <td>-0.347459</td>\n",
       "      <td>-0.457218</td>\n",
       "      <td>-0.136996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>4.123106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297132</td>\n",
       "      <td>0.313410</td>\n",
       "      <td>-0.119495</td>\n",
       "      <td>-0.421667</td>\n",
       "      <td>0.933068</td>\n",
       "      <td>-0.278325</td>\n",
       "      <td>-0.271448</td>\n",
       "      <td>-0.483791</td>\n",
       "      <td>0.014888</td>\n",
       "      <td>-0.009685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>-0.242536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050730</td>\n",
       "      <td>2.885536</td>\n",
       "      <td>-1.380379</td>\n",
       "      <td>1.087458</td>\n",
       "      <td>2.519285</td>\n",
       "      <td>-0.278325</td>\n",
       "      <td>-0.271448</td>\n",
       "      <td>-0.347459</td>\n",
       "      <td>-0.457218</td>\n",
       "      <td>-0.107389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.242536  4.123106 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536   \n",
       "1 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536  4.123106   \n",
       "2 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536   \n",
       "3 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536   \n",
       "4 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536 -0.242536   \n",
       "\n",
       "         7         8         9     ...           48        49        50  \\\n",
       "0 -0.242536 -0.242536 -0.242536    ...     0.789936 -0.421483  0.300799   \n",
       "1 -0.242536 -0.242536 -0.242536    ...     0.543534 -0.788929  1.141388   \n",
       "2 -0.242536  4.123106 -0.242536    ...    -0.442074 -0.054036 -1.380379   \n",
       "3 -0.242536 -0.242536  4.123106    ...     0.297132  0.313410 -0.119495   \n",
       "4 -0.242536 -0.242536 -0.242536    ...     0.050730  2.885536 -1.380379   \n",
       "\n",
       "         51        52        53        54        55        56        57  \n",
       "0 -0.421667  0.139960 -0.278325 -0.271448 -0.756455  1.588575  2.261191  \n",
       "1  1.842020  0.933068 -0.278325 -0.271448 -0.292927 -0.457218 -0.225818  \n",
       "2  0.332895 -0.653148 -0.278325 -0.271448 -0.347459 -0.457218 -0.136996  \n",
       "3 -0.421667  0.933068 -0.278325 -0.271448 -0.483791  0.014888 -0.009685  \n",
       "4  1.087458  2.519285 -0.278325 -0.271448 -0.347459 -0.457218 -0.107389  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all = pd.DataFrame(X_all)\n",
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train ,y_test = train_test_split(X_all, y_all, random_state= 2,test_size = 0.25,stratify = y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    \n",
    "    # Start the clock, train the classifier ,then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end - start))\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    '''Makes predictions using a fit classifier based on F1 score. '''\n",
    "    \n",
    "    # Start clock make predictions,stop clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    \n",
    "    end  = time()\n",
    "    # print and return results\n",
    "    print(\"Made predictions in {:.4f} seconds.\".format(end - start))\n",
    "    \n",
    "    return f1_score(target, y_pred,labels='H',average = 'macro'),sum(target == y_pred) / float(len(y_pred))\n",
    "\n",
    "def train_predict(clf,X_train, y_train ,X_test,y_test):\n",
    "    ''' Train and predict using a classifier based on F1 score'''\n",
    "    \n",
    "    # Indicate the classifier and the training set size\n",
    "    print(\"Trainig a {} using a training set size of...\".format(clf.__class__.__name__,))\n",
    "    \n",
    "    # train the classifier\n",
    "    train_classifier(clf, X_train,y_train)\n",
    "    \n",
    "    # print the results of prediction for both training and testing\n",
    "    f1, acc = predict_labels(clf, X_train, y_train)\n",
    "    print(f1,acc)\n",
    "    print(\"F1 score and accuracy score for training set: {:.4f}, {:.4f}. \".format(f1,acc))\n",
    "    \n",
    "    f1, acc = predict_labels(clf, X_test, y_test)\n",
    "    print(\"F1 score and accuracy score for test set: {:.4f}, {:.4f}. \".format(f1,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig a LogisticRegression using a training set size of...\n",
      "Trained model in 0.0205 seconds\n",
      "Made predictions in 0.0012 seconds.\n",
      "1.0 1.0\n",
      "F1 score and accuracy score for training set: 1.0000, 1.0000. \n",
      "Made predictions in 0.0008 seconds.\n",
      "F1 score and accuracy score for test set: 0.9412, 0.9091. \n",
      "\n",
      "Trainig a SVC using a training set size of...\n",
      "Trained model in 0.0083 seconds\n",
      "Made predictions in 0.0046 seconds.\n",
      "0.9665071770334929 0.9432314410480349\n",
      "F1 score and accuracy score for training set: 0.9665, 0.9432. \n",
      "Made predictions in 0.0019 seconds.\n",
      "F1 score and accuracy score for test set: 0.8485, 0.7662. \n",
      "\n",
      "Trainig a RandomForestClassifier using a training set size of...\n",
      "Trained model in 0.0711 seconds\n",
      "Made predictions in 0.0085 seconds.\n",
      "1.0 1.0\n",
      "F1 score and accuracy score for training set: 1.0000, 1.0000. \n",
      "Made predictions in 0.0072 seconds.\n",
      "F1 score and accuracy score for test set: 0.9315, 0.8831. \n",
      "\n",
      "Trainig a XGBClassifier using a training set size of...\n",
      "Trained model in 0.1234 seconds\n",
      "Made predictions in 0.0033 seconds.\n",
      "1.0 1.0\n",
      "F1 score and accuracy score for training set: 1.0000, 1.0000. \n",
      "Made predictions in 0.0017 seconds.\n",
      "F1 score and accuracy score for test set: 1.0000, 0.9870. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_A = LogisticRegression(solver='lbfgs',random_state = 42,multi_class='auto')\n",
    "clf_B = SVC(random_state = 912,kernel = 'rbf',gamma = 'scale')\n",
    "clf_C = RandomForestClassifier(n_estimators = 100,max_depth = 10,random_state=82)\n",
    "clf_D = xgb.XGBClassifier(seed=82)\n",
    "\n",
    "train_predict(clf_A,X_train, y_train,X_test, y_test)\n",
    "print('')\n",
    "\n",
    "train_predict(clf_B,X_train, y_train,X_test, y_test)\n",
    "print('')\n",
    "\n",
    "train_predict(clf_C,X_train, y_train,X_test, y_test)\n",
    "print('')\n",
    "\n",
    "train_predict(clf_D,X_train, y_train,X_test, y_test)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saazi/ml/env/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/saazi/ml/env/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''\n",
    "Load some data and do some cleaning\n",
    "'''\n",
    "bl = pd.read_csv('~/Documents/datasets/football/D1.csv')\n",
    "columns = [ 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HTHG', 'HTAG',\n",
    "       'HTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC',\n",
    "       'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A']\n",
    "data = bl[columns]\n",
    "cat_features = ['HomeTeam','AwayTeam','HTR']\n",
    "num_features = ['FTHG', 'FTAG', 'HTHG', 'HTAG',\n",
    "     'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC',\n",
    "       'HY', 'AY', 'HR', 'AR', 'B365H', 'B365D', 'B365A']\n",
    "\n",
    "X_all = data.drop(\"FTR\",1)\n",
    "y_all = data[\"FTR\"]\n",
    "\n",
    "scaled_data = StandardScaler().fit_transform(X_all[num_features])\n",
    "scaled = pd.DataFrame(scaled_data,columns = num_features)\n",
    "dummies = pd.get_dummies(X_all[cat_features],prefix = [col for col, col_data in X_all[cat_features].iteritems()])\n",
    "\n",
    "df = dummies.join(scaled)\n",
    "\n",
    "X_train, X_test, y_train ,y_test = train_test_split(df, y_all, random_state= 0,test_size = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regresssion...\n",
      "Accuracy on the training subset: 1.000000\n",
      "Accuracy on the testing subset: 0.896104\n",
      "\n",
      "Support Vector Machine...\n",
      "Accuracy on the training subset: 0.925764\n",
      "Accuracy on the testing subset: 0.805195\n",
      "\n",
      "Random Forest...\n",
      "Accuracy on the training subset: 1.000000\n",
      "Accuracy on the testing subset: 0.792208\n",
      "\n",
      "XGBoost Classifier...\n",
      "Accuracy on the training subset: 1.000000\n",
      "Accuracy on the testing subset: 0.974026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from matplotlib import style\n",
    "\n",
    "clf_A = LogisticRegression(solver='lbfgs',random_state = 42,multi_class='auto')\n",
    "clf_B = SVC(random_state = 912,kernel = 'rbf',gamma = 'scale')\n",
    "clf_C = RandomForestClassifier(n_estimators = 100,max_depth = 10,random_state=82)\n",
    "clf_D = xgb.XGBClassifier(seed=82)\n",
    "\n",
    "print('Logistic Regresssion...')\n",
    "clf_A.fit(X_train, y_train)\n",
    "print('Accuracy on the training subset: {:3f}'.format(clf_A.score(X_train, y_train)))\n",
    "print('Accuracy on the testing subset: {:3f}'.format(clf_A.score(X_test, y_test)))\n",
    "print('')\n",
    "\n",
    "print('Support Vector Machine...')\n",
    "clf_B.fit(X_train, y_train)\n",
    "print('Accuracy on the training subset: {:3f}'.format(clf_B.score(X_train, y_train)))\n",
    "print('Accuracy on the testing subset: {:3f}'.format(clf_B.score(X_test, y_test)))\n",
    "print('')\n",
    "\n",
    "print('Random Forest...')\n",
    "clf_C.fit(X_train, y_train)\n",
    "print('Accuracy on the training subset: {:3f}'.format(clf_C.score(X_train, y_train)))\n",
    "print('Accuracy on the testing subset: {:3f}'.format(clf_C.score(X_test, y_test)))\n",
    "print('')\n",
    "\n",
    "print('XGBoost Classifier...')\n",
    "clf_D.fit(X_train, y_train)\n",
    "print('Accuracy on the training subset: {:3f}'.format(clf_D.score(X_train, y_train)))\n",
    "print('Accuracy on the testing subset: {:3f}'.format(clf_D.score(X_test, y_test)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
